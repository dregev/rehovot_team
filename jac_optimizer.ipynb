{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "random.seed(4)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DMBI_hackathon_ddi_utils():\n",
    "    NODE_1 = 'node1'\n",
    "    NODE_2 = 'node2'\n",
    "    def __init__(self,number_of_drugs = 1434):\n",
    "        self.number_of_drugs = number_of_drugs\n",
    "\n",
    "    def write_list_to_file(self, list, path):\n",
    "        thefile = open(path, 'w')\n",
    "        for item in list:\n",
    "            thefile.write(\"%s\\n\" % item)\n",
    "        thefile.close()\n",
    "\n",
    "    def read_sparse_matrix(self,train_data):\n",
    "        print('creating matrix')\n",
    "        x = train_data[self.NODE_1]\n",
    "        y = train_data[self.NODE_2]\n",
    "        assert len(x) == len(y)\n",
    "        data = [1] * len(x)\n",
    "        m = csr_matrix((data,(x,y)), shape=(self.number_of_drugs, self.number_of_drugs),dtype='f')\n",
    "        print('m shape:', m.shape, 'm non zeros:', m.nnz)\n",
    "        assert np.allclose(m.todense(), m.T.todense(), atol=1e-8) #matrix is symmetric\n",
    "        return m.todense()#the matrix is small, sparse matrix is not necessary.\n",
    "    \n",
    "    def write_solution_to_file(self,preds,file_path, num_interactions_train):\n",
    "        #preds is assumed to be ordered by confidence level\n",
    "        #adds the header to the soution, combines the node IDs and writes the so×šution to file\n",
    "        #asserts are important. Note them.\n",
    "        \n",
    "        print('writing predictions to file: ',file_path)\n",
    "        for u, v in preds:\n",
    "           assert u < v, 'graph is undirected, predict edges where the first node id is smaller than the second only'\n",
    "        assert len(preds) == (self.number_of_drugs * self.number_of_drugs - self.number_of_drugs - num_interactions_train) / 2, \"number of predictions is equal to number of non existing edges\"\n",
    "        output = [','.join([self.NODE_1 + '_' + self.NODE_2])]+[','.join([str(p[0]) +'_' + str(p[1])]) for p in preds]\n",
    "        self.write_list_to_file(output,file_path)\n",
    "\n",
    "    def create_holdout_set(self, m_train, train_percent = 0.9):\n",
    "        # create holdout set. the set will contain both existing and non-existing edges\n",
    "        m_train_holdout = np.matrix(m_train)\n",
    "        validation_set = set()\n",
    "        for i in range(self.number_of_drugs):\n",
    "            for j in range(i+1, self.number_of_drugs):\n",
    "                if random.random() > train_percent:\n",
    "                    validation_set.add((i, j))\n",
    "                    m_train_holdout[i, j] = 0\n",
    "                    m_train_holdout[j, i] = 0\n",
    "        return m_train_holdout, validation_set\n",
    "\n",
    "    def average_precision_at_k(self, k, class_correct):\n",
    "        #return average precision at k\n",
    "        #more examples: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "        #and: https://www.kaggle.com/c/avito-prohibited-content#evaluation\n",
    "        #class_correct is a list with the binary correct label ordered by confidence level.\n",
    "        assert k <= len(class_correct) and k > 0        \n",
    "        score = 0.0\n",
    "        hits = 0.0\n",
    "        for i in range(k):\n",
    "            if class_correct[i] == 1:\n",
    "                hits += 1.0\n",
    "            score += hits / (i+1.0)\n",
    "        score /= k\n",
    "        return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simple prediction class\n",
    "class link_prediction_predictor:\n",
    "    def __init__(self, number_of_drugs):\n",
    "        self.G = nx.Graph()\n",
    "        self.G.add_nodes_from(range(number_of_drugs))\n",
    "\n",
    "    def fit(self, edge_list):\n",
    "        self.G.add_edges_from(edge_list)\n",
    "\n",
    "    def predict(self,prediction_set=None):\n",
    "        preds = nx.resource_allocation_index(self.G, ebunch=prediction_set)  \n",
    "        # if ebunch is None then all non-existent edges in the graph will be used.\n",
    "        preds = [(u1, v1) for (p, u1, v1) in sorted([(prediction, u, v) for (u, v, prediction) in preds],reverse=True)]  \n",
    "        #predictions are expected as described in write_solution_to_file. The values are suppose to be ordered by confidence.\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jac_predict(A):\n",
    "    \n",
    "    n = A.shape[0]\n",
    "    print('n:', n)\n",
    "\n",
    "    # create graph\n",
    "    x, y = A.nonzero() # x and y indices of nonzero cells (existing edges)\n",
    "    edge_list = list(zip(x,y)) \n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # compute Jackard coefficients\n",
    "    cuts = A*A\n",
    "    d = A.sum(1)\n",
    "    joins = np.tile(d, [1,n])\n",
    "    joins = joins + joins.T - cuts   \n",
    "    J_mat = cuts/joins\n",
    "    np.nan_to_num(J_mat, copy=False)    \n",
    "    \n",
    "    Score = J_mat*A*J_mat\n",
    "    np.fill_diagonal(Score, 0)    \n",
    "\n",
    "    scores = [(i , j, Score[i,j]) for j in range(n) for i in range(j) if A[i,j]==0]\n",
    "    scores = [(u1, v1, s) for (s, u1, v1) in sorted([(s, u, v) for (u, v, s) in scores], reverse=True)]  \n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating matrix\n",
      "m shape: (1434, 1434) m non zeros: 93200\n"
     ]
    }
   ],
   "source": [
    "DMBI_hackathon_ddi = DMBI_hackathon_ddi_utils()\n",
    "train_matrix = DMBI_hackathon_ddi.read_sparse_matrix(pd.read_csv('data/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluate model. \n",
    "#Note that holdout is based on random decision. \n",
    "#Test set contains new interactions that random selection does not emulate.\n",
    "\n",
    "m_train_holdout, validation_set = DMBI_hackathon_ddi.create_holdout_set(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shira\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision @ 100:  0.7373423785971178\n"
     ]
    }
   ],
   "source": [
    "preds = jac_predict(m_train_holdout)\n",
    "# x, y = m_train_holdout.nonzero() # x and y indices of nonzero cells (existing edges)\n",
    "# edge_list = list(zip(x,y)) \n",
    "# link_prediction = link_prediction_predictor(DMBI_hackathon_ddi.number_of_drugs)\n",
    "# link_prediction.fit(edge_list)\n",
    "# preds = link_prediction.predict(validation_set)\n",
    "class_correct = [train_matrix[x[0],x[1]] for x in preds]\n",
    "average_precision = DMBI_hackathon_ddi.average_precision_at_k(k=100,class_correct=class_correct)\n",
    "print('average precision @ 100: ', average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions to file:  sample_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#Create final submission file\n",
    "x,y = train_matrix.nonzero()\n",
    "num_interactions_train = len(x);assert len(x)==len(y)\n",
    "edge_list = list(zip(x,y))\n",
    "link_prediction = link_prediction_predictor(DMBI_hackathon_ddi.number_of_drugs)\n",
    "link_prediction.fit(edge_list)\n",
    "preds = link_prediction.predict()\n",
    "DMBI_hackathon_ddi.write_solution_to_file(preds,'sample_predictions.csv',num_interactions_train=num_interactions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
