{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "random.seed(4)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DMBI_hackathon_ddi_utils():\n",
    "    NODE_1 = 'node1'\n",
    "    NODE_2 = 'node2'\n",
    "    def __init__(self,number_of_drugs = 1434):\n",
    "        self.number_of_drugs = number_of_drugs\n",
    "\n",
    "    def write_list_to_file(self, list, path):\n",
    "        thefile = open(path, 'w')\n",
    "        for item in list:\n",
    "            thefile.write(\"%s\\n\" % item)\n",
    "        thefile.close()\n",
    "\n",
    "    def read_sparse_matrix(self,train_data):\n",
    "        print('creating matrix')\n",
    "        x = train_data[self.NODE_1]\n",
    "        y = train_data[self.NODE_2]\n",
    "        assert len(x) == len(y)\n",
    "        data = [1] * len(x)\n",
    "        m = csr_matrix((data,(x,y)), shape=(self.number_of_drugs, self.number_of_drugs),dtype='f')\n",
    "        print('m shape:', m.shape, 'm non zeros:', m.nnz)\n",
    "        assert np.allclose(m.todense(), m.T.todense(), atol=1e-8) #matrix is symmetric\n",
    "        return m.todense()#the matrix is small, sparse matrix is not necessary.\n",
    "    \n",
    "    def write_solution_to_file(self,preds,file_path, num_interactions_train):\n",
    "        #preds is assumed to be ordered by confidence level\n",
    "        #adds the header to the soution, combines the node IDs and writes the so×šution to file\n",
    "        #asserts are important. Note them.\n",
    "        \n",
    "        print('writing predictions to file: ',file_path)\n",
    "        for u, v in preds:\n",
    "           assert u < v, 'graph is undirected, predict edges where the first node id is smaller than the second only'\n",
    "        assert len(preds) == (self.number_of_drugs * self.number_of_drugs - self.number_of_drugs - num_interactions_train) / 2, \"number of predictions is equal to number of non existing edges\"\n",
    "        output = [','.join([self.NODE_1 + '_' + self.NODE_2])]+[','.join([str(p[0]) +'_' + str(p[1])]) for p in preds]\n",
    "        self.write_list_to_file(output,file_path)\n",
    "\n",
    "    def create_holdout_set(self, m_train, train_percent = 0.9):\n",
    "        # create holdout set. the set will contain both existing and non-existing edges\n",
    "        m_train_holdout = np.matrix(m_train)\n",
    "        validation_set = set()\n",
    "        for i in range(self.number_of_drugs):\n",
    "            for j in range(i+1, self.number_of_drugs):\n",
    "                if random.random() > train_percent:\n",
    "                    validation_set.add((i, j))\n",
    "                    m_train_holdout[i, j] = 0\n",
    "                    m_train_holdout[j, i] = 0\n",
    "        return m_train_holdout, validation_set\n",
    "\n",
    "    def average_precision_at_k(self, k, class_correct):\n",
    "        #return average precision at k\n",
    "        #more examples: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "        #and: https://www.kaggle.com/c/avito-prohibited-content#evaluation\n",
    "        #class_correct is a list with the binary correct label ordered by confidence level.\n",
    "        assert k <= len(class_correct) and k > 0        \n",
    "        score = 0.0\n",
    "        hits = 0.0\n",
    "        for i in range(k):\n",
    "            if class_correct[i] == 1:\n",
    "                hits += 1.0\n",
    "            score += hits / (i+1.0)\n",
    "        score /= k\n",
    "        return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simple prediction class\n",
    "class link_prediction_predictor:\n",
    "    def __init__(self, number_of_drugs):\n",
    "        self.G = nx.Graph()\n",
    "        self.G.add_nodes_from(range(number_of_drugs))\n",
    "\n",
    "    def fit(self, edge_list):\n",
    "        self.G.add_edges_from(edge_list)\n",
    "\n",
    "    def predict(self,prediction_set=None):\n",
    "        preds = nx.resource_allocation_index(self.G, ebunch=prediction_set)  \n",
    "        # if ebunch is None then all non-existent edges in the graph will be used.\n",
    "        preds = [(u1, v1) for (p, u1, v1) in sorted([(prediction, u, v) for (u, v, prediction) in preds],reverse=True)]  \n",
    "        #predictions are expected as described in write_solution_to_file. The values are suppose to be ordered by confidence.\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jac(A):\n",
    "    # compute Jackard coefficients    \n",
    "    cuts = A*A\n",
    "    d = A.sum(1)\n",
    "    joins = np.tile(d, [1,A.shape[0]])\n",
    "    joins = joins + joins.T - cuts   \n",
    "    J = cuts/joins\n",
    "    np.nan_to_num(J, copy=False)   \n",
    "    np.fill_diagonal(J, 1) \n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smart_thresh(A, J, k, g=10):\n",
    "    n = A.shape[0]\n",
    "    T = sorted(np.linspace(.2, .95, g), reverse=True)\n",
    "    for i_T in range(len(T)):\n",
    "        th = T[i_T]\n",
    "        J_th = (J>th).astype(int)\n",
    "        Score = J_th*A*J_th\n",
    "        np.fill_diagonal(Score, 0)\n",
    "        pos_scores = [Score[i,j] for j in range(n) for i in range(j) if (A[i,j]==0 and Score[i,j]>0)]\n",
    "        count_pos_scores = len(pos_scores)\n",
    "        #print('th = {}, count = {}'.format(th, count_pos_scores))\n",
    "        if count_pos_scores > k:\n",
    "            print('threshold {} gives count of {}'.format(th, count_pos_scores))\n",
    "            return th\n",
    "    print('threshold: {} gives count of {}'.format(th, count_pos_scores))\n",
    "    return th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jac_predict_smart_thresh(A, k, g):\n",
    "    \n",
    "    n = A.shape[0]\n",
    "    J = jac(A)  \n",
    "    Score = J*A*J\n",
    "    thresh = smart_thresh(A, J, k, g)\n",
    "    J = (J>thresh).astype(int)\n",
    "    np.fill_diagonal(J, 5) \n",
    "    \n",
    "    Score = J*A*J\n",
    "    np.fill_diagonal(Score, 0)    \n",
    "\n",
    "    scores = [(i , j, Score[i,j]) for j in range(n) for i in range(j) if A[i,j]==0]\n",
    "#    scores = [(i , j, Score[i,j]) for (i,j) in validation_set]\n",
    "    preds = [(u1, v1) for (s, u1, v1) in sorted([(s, u, v) for (u, v, s) in scores], reverse=True)]  \n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_preds(preds, A):\n",
    "    for (i,j) in preds:\n",
    "        if A[i,j]:\n",
    "            print('Error: preds contain an existing edge: ({},{})'.format(i,j))\n",
    "            return\n",
    "    print('Good: preds do not contain existing edges!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating matrix\n",
      "m shape: (1434, 1434) m non zeros: 93200\n"
     ]
    }
   ],
   "source": [
    "DMBI_hackathon_ddi = DMBI_hackathon_ddi_utils()\n",
    "train_matrix = DMBI_hackathon_ddi.read_sparse_matrix(pd.read_csv('train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluate model. \n",
    "#Note that holdout is based on random decision. \n",
    "#Test set contains new interactions that random selection does not emulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_preds(preds, m_train_holdout, train_matrix):\n",
    "#     print(len(preds))\n",
    "#     s = [x[2] for x in preds if x[2]>0]\n",
    "#     print(len(s))\n",
    "    check_preds(preds, m_train_holdout)\n",
    "    class_correct = [train_matrix[x[0],x[1]] for x in preds]\n",
    "    average_precision = DMBI_hackathon_ddi.average_precision_at_k(k=100,class_correct=class_correct)\n",
    "    print('average precision @ 100: ', average_precision)\n",
    "    average_precision = DMBI_hackathon_ddi.average_precision_at_k(k=200,class_correct=class_correct)\n",
    "    print('average precision @ 200: ', average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-763137ecf5ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#m_train_holdout, validation_set = DMBI_hackathon_ddi.create_holdout_set(train_matrix, train_percent=.9)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object does not support indexing"
     ]
    }
   ],
   "source": [
    "#m_train_holdout, validation_set = DMBI_hackathon_ddi.create_holdout_set(train_matrix, train_percent=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_methods(percent):\n",
    "    \n",
    "    print('\\ncomputing validation on', percent)\n",
    "    m_train_holdout, validation_set = DMBI_hackathon_ddi.create_holdout_set(train_matrix, train_percent=percent)\n",
    "\n",
    "    print('\\ntesting jac_predict_smart_thresh')\n",
    "    preds = jac_predict_smart_thresh(m_train_holdout, 2000, 50)\n",
    "    test_preds(preds, m_train_holdout, train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing validation on 0.9\n",
      "\n",
      "testing jac_predict_smart_thresh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shira\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.7816326530612245 gives count of 2281\n",
      "Good: preds do not contain existing edges!\n",
      "average precision @ 100:  0.9929182782068977\n",
      "average precision @ 200:  0.99300587195104\n"
     ]
    }
   ],
   "source": [
    "# self_jac 5\n",
    "test_methods(.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating matrix\n",
      "m shape: (1434, 1434) m non zeros: 93200\n",
      "threshold 0.8734693877551021 gives count of 2353\n",
      "Good: preds do not contain existing edges!\n",
      "980861\n",
      "writing predictions to file:  sample_predictions_temp.csv\n"
     ]
    }
   ],
   "source": [
    "#Create final submission file\n",
    "train_matrix = DMBI_hackathon_ddi.read_sparse_matrix(pd.read_csv('train.csv'))\n",
    "x,y = train_matrix.nonzero()\n",
    "num_interactions_train = len(x); assert len(x)==len(y)\n",
    "# edge_list = list(zip(x,y))\n",
    "# link_prediction = link_prediction_predictor(DMBI_hackathon_ddi.number_of_drugs)\n",
    "# link_prediction.fit(edge_list)\n",
    "# preds = link_prediction.predict()\n",
    "preds = jac_predict_smart_thresh(train_matrix, 2000, 50)\n",
    "check_preds(preds, train_matrix)\n",
    "print(len(preds))\n",
    "DMBI_hackathon_ddi.write_solution_to_file(preds,'sample_predictions_temp.csv',num_interactions_train=num_interactions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
