{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DMBI_hackathon_ddi_utils():\n",
    "    NODE_1 = 'node1'\n",
    "    NODE_2 = 'node2'\n",
    "    def __init__(self,number_of_drugs = 1434):\n",
    "        self.number_of_drugs =number_of_drugs\n",
    "\n",
    "    def write_list_to_file(self, list, path):\n",
    "        thefile = open(path, 'w')\n",
    "        for item in list:\n",
    "            thefile.write(\"%s\\n\" % item)\n",
    "        thefile.close()\n",
    "\n",
    "    def read_sparse_matrix(self,train_data):\n",
    "        print('creating matrix')\n",
    "        x = train_data[self.NODE_1]\n",
    "        y = train_data[self.NODE_2]\n",
    "        assert len(x) == len(y)\n",
    "        data = [1] * len(x)\n",
    "        m = csr_matrix((data,(x,y)), shape=(self.number_of_drugs, self.number_of_drugs),dtype='f')\n",
    "        print('m shape:', m.shape, 'm non zeros:', m.nnz)\n",
    "        assert np.allclose(m.todense(), m.T.todense(), atol=1e-8) #matrix is symmetric\n",
    "        return m.todense()#the matrix is small, sparse matrix is not necessary.\n",
    "    \n",
    "    def write_solution_to_file(self,preds,file_path, num_interactions_train):\n",
    "        #preds is assumed to be ordered by confidence level\n",
    "        #adds the header to the soution, combines the node IDs and writes the so×šution to file\n",
    "        #asserts are important. Note them.\n",
    "        \n",
    "        print('writing predictions to file: {file_path}')\n",
    "        for u, v in preds:\n",
    "           assert u < v, 'graph is undirected, predict edges where the first node id is smaller than the second only'\n",
    "        assert len(preds) == (self.number_of_drugs * self.number_of_drugs - self.number_of_drugs - num_interactions_train) / 2, \"number of predictions is equal to number of non existing edges\"\n",
    "        output = [','.join([self.NODE_1 + '_' + self.NODE_2])]+[','.join([str(p[0]) +'_' + str(p[1])]) for p in preds]\n",
    "        self.write_list_to_file(output,file_path)\n",
    "\n",
    "    def create_holdout_set(self,m_train,train_percent = 0.9):\n",
    "        #create holdout set. the set will contains both existing and non-existing edges.\n",
    "        m_train_holdout = np.matrix(m_train)\n",
    "        validation_set = set()\n",
    "        for i in range(self.number_of_drugs):\n",
    "            for j in range(i+1,self.number_of_drugs):\n",
    "                if random.random()>train_percent:\n",
    "                    validation_set.add((i,j))\n",
    "                    m_train_holdout[i,j] = 0\n",
    "                    m_train_holdout[j, i] = 0\n",
    "        return m_train_holdout,validation_set\n",
    "\n",
    "    def average_precision_at_k(self,k, class_correct):\n",
    "        #return average precision at k.\n",
    "        #more examples: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "        #and: https://www.kaggle.com/c/avito-prohibited-content#evaluation\n",
    "        #class_correct is a list with the binary correct label ordered by confidence level.\n",
    "        assert k <= len(class_correct) and k > 0        \n",
    "        score = 0.0\n",
    "        hits = 0.0\n",
    "        for i in range(k):\n",
    "            if class_correct[i]==1:\n",
    "                hits += 1.0\n",
    "            score += hits /(i+1.0)\n",
    "        score /= k\n",
    "        return score\n",
    "    \n",
    "    def balance_dataset(self):\n",
    "#         edges = pd.read_csv('edges.csv')\n",
    "        edges = pd.read_csv('edges_90_2200.csv')\n",
    "\n",
    "#         edges = edges.drop(columns = 0)\n",
    "        trainDataYes = edges[edges['is_edge']==1]\n",
    "        noEdge = edges[edges['is_edge']==0]\n",
    "        noEdge = noEdge.drop(['is_edge'], axis=1)\n",
    "        numEdges = len(trainDataYes)\n",
    "        trainDataNo = edges.sample(n = numEdges)\n",
    "        trainData = pd.concat([trainDataYes,trainDataNo])\n",
    "        trainData = trainData.sample(frac=1).reset_index(drop=True)\n",
    "#         print(trainData.head())\n",
    "        y = trainData['is_edge']\n",
    "#         print(y.head())\n",
    "        X = trainData.drop(['is_edge'], axis=1)\n",
    "#         print(X.head())\n",
    "        return X, y, noEdge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#simple prediction class\n",
    "class link_prediction_predictor:\n",
    "    def __init__(self,number_of_drugs):\n",
    "        self.G = nx.Graph()\n",
    "        self.G.add_nodes_from(range(number_of_drugs))\n",
    "        X, y, noEdges = DMBI_hackathon_ddi.balance_dataset()\n",
    "        self.noEdges = noEdges\n",
    "        print(self.noEdges.head())\n",
    "        cutInd = int(len(X)*0.8)\n",
    "        X_train = X.iloc[0:cutInd]\n",
    "        self.X_train = X_train.as_matrix()\n",
    "        print(X_train.head())\n",
    "        X_val = X.iloc[cutInd:]\n",
    "        self.X_val = X_val.as_matrix()       \n",
    "        y_train = y.iloc[0:cutInd]\n",
    "        self.y_train = y_train.as_matrix()\n",
    "        \n",
    "        y_val = y.iloc[cutInd:]\n",
    "        self.y_val = y_val.as_matrix()\n",
    "        \n",
    "\n",
    "    def fit(self,edge_list):\n",
    "        self.G.add_edges_from(edge_list)\n",
    "\n",
    "    def pred_random_forest(self,prediction_set=None):\n",
    "#         preds = nx.resource_allocation_index(self.G,ebunch=prediction_set)  \n",
    "#         # if ebunch is None then all non-existent edges in the graph will be used.\n",
    "#         preds = [(u1, v1) for (p, u1, v1) in sorted([(prediction, u, v) for (u, v, prediction) in preds],reverse=True)]  \n",
    "#         #predictions are expected as described in write_solution_to_file. The values are suppose to be ordered by confidence.\n",
    "        \n",
    "        \n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(self.X_train, self.y_train, sample_weight=None)\n",
    "        y_pred = clf.predict_proba(self.X_val)\n",
    "        y_pred_allEdges = clf.predict_proba(self.noEdges)\n",
    "        u = self.noEdges['node1']\n",
    "        v = self.noEdges['node2']\n",
    "        pred_unsorted = list(zip(u,v,y_pred_allEdges))\n",
    "        pred_sorted = [(u1, v1) for (p, u1, v1) in sorted([(prediction, u, v) \n",
    "                                                           for (u, v, prediction) in pred_unsorted],reverse=True)]  \n",
    "        print(self.X_val)\n",
    "        print(y_pred)\n",
    "        y_pred_vec = [1 if jj>ii else 0 for (ii,jj) in y_pred ]\n",
    "        preds = pred_sorted\n",
    "        \n",
    "        \n",
    "        '''>>> from sklearn.model_selection import KFold\n",
    "        >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "        >>> y = np.array([1, 2, 3, 4])\n",
    "        >>> kf = KFold(n_splits=2)\n",
    "        >>> kf.get_n_splits(X)\n",
    "        2\n",
    "        >>> print(kf)  \n",
    "        KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "        >>> for train_index, test_index in kf.split(X):\n",
    "        ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        ...    X_train, X_test = X[train_index], X[test_index]\n",
    "        ...    y_train, y_test = y[train_index], y[test_index]\n",
    "        TRAIN: [2 3] TEST: [0 1]\n",
    "        TRAIN: [0 1] TEST: [2 3]'''\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating matrix\n",
      "m shape: (1434, 1434) m non zeros: 93200\n"
     ]
    }
   ],
   "source": [
    "DMBI_hackathon_ddi = DMBI_hackathon_ddi_utils()\n",
    "train_matrix = DMBI_hackathon_ddi.read_sparse_matrix(pd.read_csv('train.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   node1  node2  common_friends  jaccard_coefficient  adamic_adar_index  \\\n",
      "0      0      1               0                  0.0                0.0   \n",
      "1      0      2               0                  0.0                0.0   \n",
      "2      0      3               0                  0.0                0.0   \n",
      "3      0      4               0                  0.0                0.0   \n",
      "4      0      5               0                  0.0                0.0   \n",
      "\n",
      "   resource_allocation_index  preferential_attachment  shortest_path_length  \\\n",
      "0                        0.0                      736                     3   \n",
      "1                        0.0                     2976                     3   \n",
      "2                        0.0                      176                     3   \n",
      "3                        0.0                     1120                     3   \n",
      "4                        0.0                       48                     3   \n",
      "\n",
      "   clustering_node1  degree_node1  degree_centrality_node1  \\\n",
      "0          0.633333            16                 0.011165   \n",
      "1          0.633333            16                 0.011165   \n",
      "2          0.633333            16                 0.011165   \n",
      "3          0.633333            16                 0.011165   \n",
      "4          0.633333            16                 0.011165   \n",
      "\n",
      "   closeness_centrality_node1  betweenness_centrality_node1  pagerank_node1  \\\n",
      "0                    0.350029                       0.00001         0.00034   \n",
      "1                    0.350029                       0.00001         0.00034   \n",
      "2                    0.350029                       0.00001         0.00034   \n",
      "3                    0.350029                       0.00001         0.00034   \n",
      "4                    0.350029                       0.00001         0.00034   \n",
      "\n",
      "   clustering_node2  degree_node2  degree_centrality_node2  \\\n",
      "0          0.523671            46                 0.032100   \n",
      "1          0.173205           186                 0.129798   \n",
      "2          0.181818            11                 0.007676   \n",
      "3          0.411594            70                 0.048849   \n",
      "4          0.000000             3                 0.002094   \n",
      "\n",
      "   closeness_centrality_node2  betweenness_centrality_node2  pagerank_node2  \n",
      "0                    0.402034                      0.000081        0.000573  \n",
      "1                    0.476989                      0.004939        0.002014  \n",
      "2                    0.378156                      0.001414        0.000406  \n",
      "3                    0.423831                      0.000219        0.000793  \n",
      "4                    0.319872                      0.000651        0.000230  \n",
      "   node1  node2  common_friends  jaccard_coefficient  adamic_adar_index  \\\n",
      "0   1000   1392               6             0.044335           1.719773   \n",
      "1    877    886              96             0.022099           0.837057   \n",
      "2    583    628               1             0.826087           4.112138   \n",
      "3    466    572               0             0.008475           0.182880   \n",
      "4    353    479              29             0.000000           0.000000   \n",
      "\n",
      "   resource_allocation_index  preferential_attachment  shortest_path_length  \\\n",
      "0                   0.050649                    10875                     1   \n",
      "1                   0.033842                     8514                     1   \n",
      "2                   0.192680                      440                     2   \n",
      "3                   0.004219                     1900                     1   \n",
      "4                   0.000000                     4608                     1   \n",
      "\n",
      "   clustering_node1  degree_node1  degree_centrality_node1  \\\n",
      "0          0.118056           251                 0.175157   \n",
      "1          0.222126           145                 0.101186   \n",
      "2          0.236102            94                 0.065597   \n",
      "3          0.167089            80                 0.055827   \n",
      "4          0.189333           126                 0.087927   \n",
      "\n",
      "   closeness_centrality_node1  betweenness_centrality_node1  pagerank_node1  \\\n",
      "0                    0.502901                      0.030123        0.003836   \n",
      "1                    0.473299                      0.001317        0.001485   \n",
      "2                    0.476989                      0.001636        0.001107   \n",
      "3                    0.433093                      0.012130        0.001649   \n",
      "4                    0.473140                      0.003153        0.001360   \n",
      "\n",
      "   clustering_node2  degree_node2  degree_centrality_node2  \\\n",
      "0          0.263736            14                 0.009770   \n",
      "1          0.244666           220                 0.153524   \n",
      "2          0.000000             1                 0.000698   \n",
      "3          0.000000             3                 0.002094   \n",
      "4          0.338158            96                 0.066992   \n",
      "\n",
      "   closeness_centrality_node2  betweenness_centrality_node2  pagerank_node2  \n",
      "0                    0.415938                      0.000206        0.000305  \n",
      "1                    0.501646                      0.003959        0.002188  \n",
      "2                    0.332967                      0.000000        0.000116  \n",
      "3                    0.323327                      0.000010        0.000168  \n",
      "4                    0.467947                      0.001346        0.001025  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-29aa7411ee67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlink_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_prediction_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDMBI_hackathon_ddi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_drugs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlink_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_random_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# acc = sum([1 if jj==ii else 0 for (ii,jj) in zip(preds,link_prediction.y_val)])/len(preds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# print(acc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-e42e761c5c13>\u001b[0m in \u001b[0;36mpred_random_forest\u001b[1;34m(self, prediction_set)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mpred_unsorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_allEdges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         pred_sorted = [(u1, v1) for (p, u1, v1) in sorted([(prediction, u, v) \n\u001b[1;32m---> 40\u001b[1;33m                                                            for (u, v, prediction) in pred_unsorted],reverse=True)]  \n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "#Evaluate model. \n",
    "#Note that holdout is based on random decision. \n",
    "#Test set contains new interactions that random selection does not emulate.\n",
    "\n",
    "m_train_holdout,validation_set = DMBI_hackathon_ddi.create_holdout_set(train_matrix)\n",
    "x,y = m_train_holdout.nonzero() #x and y indeices of nonzero cells (existing edges)\n",
    "edge_list = list(zip(x,y)) \n",
    "link_prediction = link_prediction_predictor(DMBI_hackathon_ddi.number_of_drugs)\n",
    "link_prediction.fit(edge_list)\n",
    "preds = link_prediction.pred_random_forest(validation_set)\n",
    "# acc = sum([1 if jj==ii else 0 for (ii,jj) in zip(preds,link_prediction.y_val)])/len(preds)\n",
    "# print(acc)\n",
    "\n",
    "# class_correct = [train_matrix[x[0],x[1]] for x in preds]\n",
    "# average_precision = DMBI_hackathon_ddi.average_precision_at_k(k=100,class_correct=class_correct)\n",
    "# print('average precision @ 100: ' + str(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83804\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "writing predictions to file: {file_path}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-880360f294f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlink_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_random_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mDMBI_hackathon_ddi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_solution_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sample_predictions.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_interactions_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_interactions_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-e9351cc6b1ee>\u001b[0m in \u001b[0;36mwrite_solution_to_file\u001b[1;34m(self, preds, file_path, num_interactions_train)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'writing predictions to file: {file_path}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m            \u001b[1;32massert\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'graph is undirected, predict edges where the first node id is smaller than the second only'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_drugs\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_drugs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_drugs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnum_interactions_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"number of predictions is equal to number of non existing edges\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#Create final submission file\n",
    "x,y = train_matrix.nonzero()\n",
    "num_interactions_train = len(x);assert len(x)==len(y)\n",
    "edge_list = list(zip(x,y))\n",
    "link_prediction = link_prediction_predictor(DMBI_hackathon_ddi.number_of_drugs)\n",
    "link_prediction.fit(edge_list)\n",
    "preds = link_prediction.pred_random_forest()\n",
    "DMBI_hackathon_ddi.write_solution_to_file(preds,'sample_predictions.csv',num_interactions_train=num_interactions_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
